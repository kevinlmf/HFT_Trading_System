#!/bin/bash
# å¿«é€Ÿæ€§èƒ½æµ‹è¯•è„šæœ¬
# å¿«é€ŸæŸ¥çœ‹QDBå’ŒOptimizationçš„æ€§èƒ½

set -e

echo ""
echo "============================================================"
echo "     QDB & Optimization æ€§èƒ½å¿«é€Ÿæµ‹è¯•"
echo "============================================================"
echo ""

# æ£€æŸ¥Python
if ! command -v python3 &> /dev/null; then
    echo "âŒ Error: python3 not found"
    exit 1
fi

# æµ‹è¯•1: QDBåŠ è½½é€Ÿåº¦
echo "1ï¸âƒ£  æµ‹è¯•QDBæ•°æ®åŠ è½½é€Ÿåº¦..."
echo "----------------------------------------"
python3 -c "
import sys
import time
sys.path.insert(0, '.')
from Data.qdb import create_qdb
import pandas as pd
import numpy as np
from datetime import datetime

# åˆ›å»ºQDB
qdb = create_qdb(base_path='./Data/datasets/qdb_test')

# ç”Ÿæˆæµ‹è¯•æ•°æ®
dates = pd.date_range(start='2024-01-01', periods=1000, freq='1H')
df = pd.DataFrame({
    'symbol': 'TEST',
    'last_price': 100 + np.cumsum(np.random.randn(len(dates)) * 0.1),
    'volume': np.random.randint(1000, 10000, len(dates)),
}, index=dates)

# å­˜å‚¨
print('  å­˜å‚¨æ•°æ®...')
start = time.time()
qdb.store(symbol='TEST', df=df, data_version='test')
store_time = (time.time() - start) * 1000
print(f'  âœ“ å­˜å‚¨æ—¶é—´: {store_time:.2f}ms')

# åŠ è½½
print('  åŠ è½½æ•°æ®...')
start = time.time()
loaded = qdb.load(symbol='TEST', start='2024-01-01', end='2024-01-10')
load_time = (time.time() - start) * 1000
print(f'  âœ“ åŠ è½½æ—¶é—´: {load_time:.2f}ms ({len(loaded)} æ¡è®°å½•)')

# ç¼“å­˜æµ‹è¯•
print('  ç¼“å­˜æµ‹è¯•...')
start = time.time()
cached = qdb.load(symbol='TEST', start='2024-01-01', end='2024-01-10')
cache_time = (time.time() - start) * 1000
print(f'  âœ“ ç¼“å­˜æ—¶é—´: {cache_time:.2f}ms')
if cache_time > 0:
    print(f'  âœ“ åŠ é€Ÿæ¯”: {load_time/cache_time:.1f}x')

# ç¼“å­˜ç»Ÿè®¡
stats = qdb.get_cache_stats()
print(f'  âœ“ ç¼“å­˜å‘½ä¸­ç‡: {stats[\"hit_rate\"]*100:.1f}%')
"

echo ""
echo "2ï¸âƒ£  æµ‹è¯•Optimizationæ ˆæ€§èƒ½..."
echo "----------------------------------------"
python3 -c "
import sys
import time
import numpy as np
sys.path.insert(0, '.')

try:
    from Optimization.optimized_optimization_stack import EnhancedOptimizationStack
    from Optimization.optimization_stack import ModelObjective
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_samples, n_assets = 1000, 50
    returns = np.random.randn(n_samples, n_assets).astype(np.float32) * 0.02
    
    print(f'  æµ‹è¯•æ•°æ®: {n_samples}æ ·æœ¬, {n_assets}èµ„äº§')
    
    # åæ–¹å·®çŸ©é˜µè®¡ç®—
    print('  åæ–¹å·®çŸ©é˜µè®¡ç®—...')
    stack = EnhancedOptimizationStack(use_qdb=False)
    
    # æ ‡å‡†è®¡ç®—
    start = time.time()
    cov_std = np.cov(returns, rowvar=False)
    time_std = (time.time() - start) * 1000
    print(f'  âœ“ æ ‡å‡†è®¡ç®—: {time_std:.2f}ms')
    
    # ç¼“å­˜è®¡ç®—
    start = time.time()
    cov_cached = stack.data_loader.get_covariance_matrix(returns, use_cache=True, cache_key='test')
    time_cached1 = (time.time() - start) * 1000
    print(f'  âœ“ ä¼˜åŒ–è®¡ç®—: {time_cached1:.2f}ms')
    
    # ç¼“å­˜å‘½ä¸­
    start = time.time()
    cov_cached2 = stack.data_loader.get_covariance_matrix(returns, use_cache=True, cache_key='test')
    time_cached2 = (time.time() - start) * 1000
    print(f'  âœ“ ç¼“å­˜å‘½ä¸­: {time_cached2:.2f}ms')
    if time_cached2 > 0:
        print(f'  âœ“ åŠ é€Ÿæ¯”: {time_std/time_cached2:.0f}x')
    
    # å†…å­˜ä¼˜åŒ–
    print('  å†…å­˜ä¼˜åŒ–...')
    returns_f64 = returns.astype(np.float64)
    returns_f32 = returns.astype(np.float32)
    size_f64 = returns_f64.nbytes / 1024
    size_f32 = returns_f32.nbytes / 1024
    print(f'  âœ“ float64: {size_f64:.1f}KB')
    print(f'  âœ“ float32: {size_f32:.1f}KB')
    print(f'  âœ“ å†…å­˜èŠ‚çœ: {(1-size_f32/size_f64)*100:.1f}%')
    
except ImportError as e:
    print(f'  âš ï¸  Optimizationæ¨¡å—ä¸å¯ç”¨: {e}')
"

echo ""
echo "3ï¸âƒ£  æµ‹è¯•ä¼˜åŒ–ç´¢å¼•å™¨æ€§èƒ½..."
echo "----------------------------------------"
python3 -c "
import sys
import time
import numpy as np
from datetime import datetime
sys.path.insert(0, '.')

try:
    from Data.qdb.improved_optimized_indexer import ImprovedOptimizedIndexer
    from datetime import timedelta
    
    # åˆ›å»ºç´¢å¼•å™¨
    indexer = ImprovedOptimizedIndexer(base_path='./Data/datasets/qdb_indexer_test')
    
    # åˆ›å»ºæµ‹è¯•ç´¢å¼•ï¼ˆæ¨¡æ‹Ÿå¤šä¸ªæ–‡ä»¶ï¼‰
    n_files = 50
    time_ranges = []
    for i in range(n_files):
        start_time = datetime(2024, 1, 1) + timedelta(days=i*7)
        end_time = start_time + timedelta(days=7)
        time_ranges.append((start_time, end_time, f'data/file_{i}.parquet'))
    
    time_ranges.sort(key=lambda x: x[0])
    end_times = np.array([tr[1].timestamp() for tr in time_ranges])
    indexer._time_index['TEST'] = (time_ranges, end_times)
    
    # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
    print(f'  æµ‹è¯•æŸ¥è¯¢ ({n_files} ä¸ªæ–‡ä»¶)...')
    start = time.time()
    for _ in range(100):
        files = indexer.find_files_optimized('TEST', datetime(2024, 1, 1), datetime(2024, 12, 31))
    query_time = (time.time() - start) / 100 * 1000
    print(f'  âœ“ å¹³å‡æŸ¥è¯¢æ—¶é—´: {query_time:.3f}ms')
    print(f'  âœ“ å¤æ‚åº¦: O(log n)')
    
except ImportError as e:
    print(f'  âš ï¸  ä¼˜åŒ–ç´¢å¼•å™¨ä¸å¯ç”¨: {e}')
except Exception as e:
    print(f'  âš ï¸  æµ‹è¯•å¤±è´¥: {e}')
"

echo ""
echo "============================================================"
echo "æµ‹è¯•å®Œæˆï¼"
echo "============================================================"
echo ""
echo "ğŸ’¡ æç¤º:"
echo "  - è¿è¡Œå®Œæ•´æµ‹è¯•: python3 scripts/benchmark_qdb.py"
echo "  - æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: cat PERFORMANCE_GUIDE.md"
echo ""

