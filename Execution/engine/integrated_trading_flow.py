"""
Integrated Trading Flow
æ•´åˆå®Œæ•´çš„äº¤æ˜“æµç¨‹ï¼šæ•°æ®å‡†å¤‡ -> ç­–ç•¥å¯¹æ¯” -> é£é™©æ§åˆ¶ -> ä»“ä½ç®¡ç† -> æ‰§è¡Œ
"""
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Callable, Any
from pathlib import Path
import sys
import os
import importlib.util
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from Risk_Control.portfolio_manager import RiskModel
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå®šä¹‰åŸºæœ¬çš„ RiskModel
    from enum import Enum
    class RiskModel(Enum):
        EQUAL_WEIGHT = "equal_weight"
        INVERSE_VOLATILITY = "inverse_volatility"
        MEAN_VARIANCE = "mean_variance"
        RISK_PARITY = "risk_parity"
        BLACK_LITTERMAN = "black_litterman"
        HIERARCHICAL_RISK_PARITY = "hrp"

try:
    from Strategy_Construction.strategy_registry import get_strategy, list_strategies
except ImportError:
    def get_strategy(name: str):
        return None
    def list_strategies():
        return []

try:
    from Evaluation.strategy_benchmark import StrategyBenchmark
except ImportError:
    StrategyBenchmark = None

try:
    from Execution.engine.smart_executor import SmartExecutor
except ImportError:
    SmartExecutor = None

# ç›´æ¥å¯¼å…¥hft_metricsï¼Œé¿å…é€šè¿‡__init__.pyï¼ˆå¯èƒ½æœ‰å…¶ä»–ä¾èµ–é—®é¢˜ï¼‰
try:
    import importlib.util
    hft_metrics_path = Path(__file__).parent.parent.parent / "Evaluation" / "hft_metrics.py"
    if hft_metrics_path.exists():
        spec = importlib.util.spec_from_file_location("hft_metrics", hft_metrics_path)
        hft_metrics_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(hft_metrics_module)
        HFTEvaluator = hft_metrics_module.HFTEvaluator
        HFTMetrics = hft_metrics_module.HFTMetrics
    else:
        HFTEvaluator = None
        HFTMetrics = None
except Exception as e:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œè®¾ç½®ä¸ºNoneï¼ˆä¸å½±å“å…¶ä»–åŠŸèƒ½ï¼‰
    HFTEvaluator = None
    HFTMetrics = None


def create_sample_strategies() -> Dict[str, Callable]:
    """
    åˆ›å»ºç¤ºä¾‹ç­–ç•¥ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿç­–ç•¥ã€MLã€RLå’ŒLLMæ–¹æ³•
    
    Returns:
        ç­–ç•¥å­—å…¸ {name: strategy_function}
    """
    strategies = {}
    
    # ========== ä¼ ç»Ÿç­–ç•¥ ==========
    
    # åŠ¨é‡ç­–ç•¥
    def momentum_strategy(data: pd.DataFrame, lookback: int = 20) -> pd.Series:
        """ç®€å•åŠ¨é‡ç­–ç•¥ï¼šå¦‚æœè¿‡å»Nå¤©ä¸Šæ¶¨ï¼Œä¹°å…¥ä¿¡å·"""
        if len(data) < lookback:
            return pd.Series([0] * len(data), index=data.index)
        prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
        returns = prices.pct_change(lookback)
        signals = (returns > 0.02).astype(int) - (returns < -0.02).astype(int)
        return signals.fillna(0)
    
    # å‡å€¼å›å½’ç­–ç•¥
    def mean_reversion_strategy(data: pd.DataFrame, lookback: int = 20) -> pd.Series:
        """å‡å€¼å›å½’ç­–ç•¥ï¼šä»·æ ¼åç¦»å‡å€¼æ—¶åå‘äº¤æ˜“"""
        if len(data) < lookback:
            return pd.Series([0] * len(data), index=data.index)
        prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
        ma = prices.rolling(lookback).mean()
        std = prices.rolling(lookback).std()
        z_score = (prices - ma) / std
        signals = (-(z_score > 1.5).astype(int) + (z_score < -1.5).astype(int))
        return signals.fillna(0)
    
    strategies['momentum'] = momentum_strategy
    strategies['mean_reversion'] = mean_reversion_strategy
    
    # ========== ML ç­–ç•¥ ==========
    
    # Random Forest ç­–ç•¥
    def ml_random_forest_strategy(data: pd.DataFrame) -> pd.Series:
        """åŸºäºéšæœºæ£®æ—çš„MLç­–ç•¥"""
        try:
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.preprocessing import StandardScaler
            import numpy as np
            
            if len(data) < 50:
                return pd.Series([0] * len(data), index=data.index)
            
            prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
            returns = prices.pct_change().fillna(0)
            
            # ç‰¹å¾å·¥ç¨‹
            features = []
            for lookback in [5, 10, 20]:
                features.append(returns.rolling(lookback).mean())
                features.append(returns.rolling(lookback).std())
                features.append(prices.rolling(lookback).mean() / prices - 1)
            
            feature_df = pd.concat(features, axis=1).fillna(0)
            
            # åˆ›å»ºæ ‡ç­¾ï¼ˆæœªæ¥æ”¶ç›Šæ–¹å‘ï¼‰
            forward_returns = returns.shift(-1).fillna(0)
            labels = (forward_returns > 0).astype(int) - (forward_returns < 0).astype(int)
            
            # è®­ç»ƒæ•°æ®å‡†å¤‡
            train_size = min(200, len(feature_df) // 2)
            if train_size < 20:
                return pd.Series([0] * len(data), index=data.index)
            
            X_train = feature_df.iloc[:train_size].values
            y_train = labels.iloc[:train_size].values
            
            # è®­ç»ƒæ¨¡å‹
            model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            X_test = feature_df.iloc[train_size:].values
            if len(X_test) == 0:
                return pd.Series([0] * len(data), index=data.index)
            
            predictions = model.predict(X_test)
            
            # ç»„åˆä¿¡å·
            signals = pd.Series([0] * train_size, index=feature_df.iloc[:train_size].index)
            signals = pd.concat([signals, pd.Series(predictions, index=feature_df.iloc[train_size:].index)])
            signals = signals.reindex(data.index, fill_value=0)
            
            return signals.fillna(0)
        except Exception as e:
            # å¦‚æœMLå¤±è´¥ï¼Œè¿”å›é›¶ä¿¡å·
            return pd.Series([0] * len(data), index=data.index)
    
    strategies['ml_random_forest'] = ml_random_forest_strategy
    
    # XGBoost ç­–ç•¥
    def ml_xgboost_strategy(data: pd.DataFrame) -> pd.Series:
        """åŸºäºXGBoostçš„MLç­–ç•¥"""
        try:
            import xgboost as xgb
            import numpy as np
            
            if len(data) < 50:
                return pd.Series([0] * len(data), index=data.index)
            
            prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
            returns = prices.pct_change().fillna(0)
            
            # ç‰¹å¾å·¥ç¨‹
            features = []
            for lookback in [5, 10, 20, 30]:
                features.append(returns.rolling(lookback).mean())
                features.append(returns.rolling(lookback).std())
                if 'volume' in data.columns:
                    features.append(data['volume'].rolling(lookback).mean() / data['volume'] - 1)
            
            feature_df = pd.concat(features, axis=1).fillna(0)
            
            # åˆ›å»ºæ ‡ç­¾
            forward_returns = returns.shift(-1).fillna(0)
            labels = (forward_returns > 0).astype(int)
            
            # è®­ç»ƒæ•°æ®å‡†å¤‡
            train_size = min(200, len(feature_df) // 2)
            if train_size < 20:
                return pd.Series([0] * len(data), index=data.index)
            
            X_train = feature_df.iloc[:train_size].values
            y_train = labels.iloc[:train_size].values
            
            # è®­ç»ƒæ¨¡å‹
            model = xgb.XGBClassifier(n_estimators=50, max_depth=4, random_state=42, n_jobs=-1)
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            X_test = feature_df.iloc[train_size:].values
            if len(X_test) == 0:
                return pd.Series([0] * len(data), index=data.index)
            
            predictions = model.predict(X_test)
            probabilities = model.predict_proba(X_test)[:, 1]
            
            # è½¬æ¢é¢„æµ‹ä¸ºä¿¡å·ï¼ˆä½¿ç”¨æ¦‚ç‡é˜ˆå€¼ï¼‰
            signals_raw = (probabilities > 0.6).astype(int) - (probabilities < 0.4).astype(int)
            
            # ç»„åˆä¿¡å·
            signals = pd.Series([0] * train_size, index=feature_df.iloc[:train_size].index)
            signals = pd.concat([signals, pd.Series(signals_raw, index=feature_df.iloc[train_size:].index)])
            signals = signals.reindex(data.index, fill_value=0)
            
            return signals.fillna(0)
        except ImportError:
            # XGBoostæœªå®‰è£…ï¼Œè¿”å›é›¶ä¿¡å·
            return pd.Series([0] * len(data), index=data.index)
        except Exception:
            return pd.Series([0] * len(data), index=data.index)
    
    try:
        import xgboost
        strategies['ml_xgboost'] = ml_xgboost_strategy
    except ImportError:
        pass
    
    # ========== RL ç­–ç•¥ ==========
    
    # ç®€å•RLç­–ç•¥ï¼ˆåŸºäºç­–ç•¥æ¢¯åº¦çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰
    def rl_simple_strategy(data: pd.DataFrame) -> pd.Series:
        """åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç®€åŒ–ç­–ç•¥"""
        try:
            if len(data) < 50:
                return pd.Series([0] * len(data), index=data.index)
            
            prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
            returns = prices.pct_change().fillna(0)
            
            # çŠ¶æ€ç‰¹å¾
            state_features = []
            for lookback in [5, 10, 20]:
                state_features.append(returns.rolling(lookback).mean())
                state_features.append(returns.rolling(lookback).std())
            
            state_df = pd.concat(state_features, axis=1).fillna(0)
            
            # ç®€å•çš„RLç­–ç•¥ï¼šåŸºäºçŠ¶æ€å€¼å‡½æ•°çš„é˜ˆå€¼å†³ç­–
            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…RLéœ€è¦è®­ç»ƒè¿‡ç¨‹
            signals = pd.Series([0] * len(data), index=data.index)
            
            for i in range(20, len(state_df)):
                state = state_df.iloc[i].values
                
                # ç®€å•çš„ç­–ç•¥ï¼šå¦‚æœå¤šä¸ªç‰¹å¾éƒ½ä¸ºæ­£ï¼Œä¹°å…¥ï¼›éƒ½ä¸ºè´Ÿï¼Œå–å‡º
                positive_features = np.sum(state > 0)
                negative_features = np.sum(state < 0)
                
                if positive_features >= len(state) * 0.6:
                    signals.iloc[i] = 1
                elif negative_features >= len(state) * 0.6:
                    signals.iloc[i] = -1
            
            return signals.fillna(0)
        except Exception:
            return pd.Series([0] * len(data), index=data.index)
    
    strategies['rl_simple'] = rl_simple_strategy
    
    # ========== LLM ç­–ç•¥ ==========
    
    # LLMå¢å¼ºç­–ç•¥ï¼ˆä½¿ç”¨LLMåˆ†æå¸‚åœºæƒ…ç»ªå’Œæ¨¡å¼ï¼‰
    def llm_sentiment_strategy(data: pd.DataFrame) -> pd.Series:
        """åŸºäºLLMæƒ…ç»ªåˆ†æçš„ç­–ç•¥"""
        try:
            if len(data) < 30:
                return pd.Series([0] * len(data), index=data.index)
            
            prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
            returns = prices.pct_change().fillna(0)
            
            # æ¨¡æ‹ŸLLMåˆ†æï¼šåŸºäºä»·æ ¼æ¨¡å¼è¯†åˆ«
            # å®é™…LLMç­–ç•¥éœ€è¦æ¥å…¥çœŸå®çš„LLM APIï¼ˆå¦‚GPT-4, Claudeç­‰ï¼‰
            
            signals = pd.Series([0] * len(data), index=data.index)
            
            # æ£€æµ‹ä»·æ ¼æ¨¡å¼
            for i in range(20, len(prices)):
                recent_prices = prices.iloc[i-20:i]
                recent_returns = returns.iloc[i-20:i]
                
                # æ¨¡å¼1ï¼šä¸Šå‡è¶‹åŠ¿
                if recent_prices.iloc[-1] > recent_prices.iloc[0] * 1.02:
                    if recent_returns.mean() > 0:
                        signals.iloc[i] = 1  # ä¹°å…¥ä¿¡å·
                
                # æ¨¡å¼2ï¼šä¸‹é™è¶‹åŠ¿
                elif recent_prices.iloc[-1] < recent_prices.iloc[0] * 0.98:
                    if recent_returns.mean() < 0:
                        signals.iloc[i] = -1  # å–å‡ºä¿¡å·
                
                # æ¨¡å¼3ï¼šæ³¢åŠ¨åŠ å‰§ï¼ˆå¯èƒ½çš„è½¬æŠ˜ç‚¹ï¼‰
                elif recent_returns.std() > returns.iloc[:i].std() * 1.5:
                    # åœ¨æ³¢åŠ¨åŠ å‰§æ—¶å‡å°‘äº¤æ˜“
                    signals.iloc[i] = 0
            
            return signals.fillna(0)
        except Exception:
            return pd.Series([0] * len(data), index=data.index)
    
    strategies['llm_sentiment'] = llm_sentiment_strategy
    
    # LLMæ¨¡å¼è¯†åˆ«ç­–ç•¥
    def llm_pattern_strategy(data: pd.DataFrame) -> pd.Series:
        """åŸºäºLLMæ¨¡å¼è¯†åˆ«çš„ç­–ç•¥"""
        try:
            if len(data) < 40:
                return pd.Series([0] * len(data), index=data.index)
            
            prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
            returns = prices.pct_change().fillna(0)
            
            signals = pd.Series([0] * len(data), index=data.index)
            
            # è¯†åˆ«æŠ€æœ¯å½¢æ€
            for i in range(30, len(prices)):
                window = prices.iloc[i-30:i]
                
                # å¤´è‚©é¡¶/åº•å½¢æ€æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                peaks = []
                troughs = []
                
                for j in range(1, len(window)-1):
                    if window.iloc[j] > window.iloc[j-1] and window.iloc[j] > window.iloc[j+1]:
                        peaks.append((j, window.iloc[j]))
                    elif window.iloc[j] < window.iloc[j-1] and window.iloc[j] < window.iloc[j+1]:
                        troughs.append((j, window.iloc[j]))
                
                # å¦‚æœæ£€æµ‹åˆ°æ˜æ˜¾çš„ä¸Šå‡æ¨¡å¼
                if len(peaks) >= 2:
                    if peaks[-1][1] > peaks[0][1] * 1.01:
                        signals.iloc[i] = 1
                
                # å¦‚æœæ£€æµ‹åˆ°æ˜æ˜¾çš„ä¸‹é™æ¨¡å¼
                if len(troughs) >= 2:
                    if troughs[-1][1] < troughs[0][1] * 0.99:
                        signals.iloc[i] = -1
            
            return signals.fillna(0)
        except Exception:
            return pd.Series([0] * len(data), index=data.index)
    
    strategies['llm_pattern'] = llm_pattern_strategy
    
    return strategies


def create_sample_data(n_records: int = 1000) -> pd.DataFrame:
    """
    åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•
    
    Args:
        n_records: è®°å½•æ•°é‡
        
    Returns:
        åŒ…å«ä»·æ ¼æ•°æ®çš„ DataFrame
    """
    np.random.seed(42)
    dates = pd.date_range(end=datetime.now(), periods=n_records, freq='H')
    
    # ç”Ÿæˆéšæœºæ¸¸èµ°ä»·æ ¼
    returns = np.random.randn(n_records) * 0.01
    prices = 100 * np.exp(np.cumsum(returns))
    
    data = pd.DataFrame({
        'timestamp': dates,
        'price': prices,
        'close': prices,
        'open': prices * (1 + np.random.randn(n_records) * 0.001),
        'high': prices * (1 + np.abs(np.random.randn(n_records) * 0.002)),
        'low': prices * (1 - np.abs(np.random.randn(n_records) * 0.002)),
        'volume': np.random.randint(1000, 10000, n_records)
    })
    
    data.set_index('timestamp', inplace=True)
    return data


class IntegratedTradingFlow:
    """
    æ•´åˆäº¤æ˜“æµç¨‹
    
    æ•´åˆä»¥ä¸‹åŠŸèƒ½ï¼š
    1. æ•°æ®å‡†å¤‡å’Œæ¸…ç†
    2. ç­–ç•¥å¯¹æ¯”å’Œè¯„ä¼°
    3. é£é™©æ§åˆ¶
    4. ä»“ä½ç®¡ç†
    5. æ™ºèƒ½æ‰§è¡Œ
    """
    
    def __init__(
        self,
        initial_capital: float = 100000.0,
        risk_model: RiskModel = RiskModel.RISK_PARITY,
        monte_carlo_paths: int = 100000,
        risk_free_rate: float = 0.02,
        periods_per_year: int = 252
    ):
        """
        åˆå§‹åŒ–æ•´åˆäº¤æ˜“æµç¨‹
        
        Args:
            initial_capital: åˆå§‹èµ„é‡‘
            risk_model: é£é™©æ¨¡å‹
            monte_carlo_paths: Monte Carlo æ¨¡æ‹Ÿè·¯å¾„æ•°
            risk_free_rate: æ— é£é™©åˆ©ç‡
            periods_per_year: æ¯å¹´äº¤æ˜“å‘¨æœŸæ•°
        """
        self.initial_capital = initial_capital
        self.risk_model = risk_model
        self.monte_carlo_paths = monte_carlo_paths
        self.risk_free_rate = risk_free_rate
        self.periods_per_year = periods_per_year
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.executor = SmartExecutor() if SmartExecutor else None
        self.benchmark = StrategyBenchmark() if StrategyBenchmark else None
        
        # åˆå§‹åŒ–HFTè¯„ä¼°å™¨ï¼ˆç›´æ¥å¯¼å…¥é¿å…__init__ä¾èµ–é—®é¢˜ï¼‰
        if HFTEvaluator:
            try:
                self.hft_evaluator = HFTEvaluator()
                print(f"  âœ“ HFT Metrics evaluator enabled")
            except Exception as e:
                print(f"  âš ï¸  HFT Metrics evaluator initialization failed: {e}")
                self.hft_evaluator = None
        else:
            self.hft_evaluator = None
        
        print(f"âœ“ Integrated Trading Flow initialized")
        print(f"  Initial Capital: ${initial_capital:,.2f}")
        print(f"  Risk Model: {risk_model.value if hasattr(risk_model, 'value') else risk_model}")
        print(f"  Monte Carlo Paths: {monte_carlo_paths:,}")
    
    def execute_complete_flow_with_position_management(
        self,
        data: pd.DataFrame,
        strategies: Optional[Dict[str, Callable]] = None,
        symbols: Optional[List[str]] = None,
        force_slippage_impl: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´äº¤æ˜“æµç¨‹ï¼ˆåŒ…å«ä»“ä½ç®¡ç†ï¼‰
        
        Args:
            data: å¸‚åœºæ•°æ®
            strategies: ç­–ç•¥å­—å…¸ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤ç­–ç•¥
            symbols: äº¤æ˜“æ ‡çš„åˆ—è¡¨
            force_slippage_impl: å¼ºåˆ¶ä½¿ç”¨çš„ slippage å®ç°
            
        Returns:
            åŒ…å«æ‰€æœ‰ç»“æœçš„å­—å…¸
        """
        print("\n" + "=" * 80)
        print("Executing Complete Trading Flow with Position Management")
        print("=" * 80)
        
        # 1. å‡†å¤‡æ•°æ®
        print("\n[1/5] Preparing data...")
        if data is None or len(data) == 0:
            print("  âš ï¸  No data provided, creating sample data")
            data = create_sample_data(n_records=1000)
        
        # ç¡®ä¿æœ‰ close åˆ—
        if 'close' not in data.columns and 'price' in data.columns:
            data['close'] = data['price']
        elif 'close' not in data.columns:
            data['close'] = data.iloc[:, 0]
        
        print(f"  âœ“ Data prepared: {len(data)} records")
        print(f"  âœ“ Date range: {data.index[0]} to {data.index[-1]}")
        
        # 2. å‡†å¤‡ç­–ç•¥ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰
        print("\n[2/5] Preparing strategies...")
        if strategies is None:
            strategies = create_sample_strategies()
            print(f"  âœ“ Using default strategies: {list(strategies.keys())}")
        else:
            print(f"  âœ“ Using provided strategies: {list(strategies.keys())}")
        
        # å¯é€‰ï¼šåº”ç”¨HFTä¼˜åŒ–
        enable_optimization = os.environ.get('ENABLE_HFT_OPTIMIZATION', 'false').lower() == 'true'
        if enable_optimization:
            try:
                from Optimization.hft_optimizer import HFTOptimizer
                print("\n  ğŸ”§ Applying HFT optimizations...")
                optimizer = HFTOptimizer()
                optimized_strategies = {}
                for name, strategy_func in strategies.items():
                    print(f"    - Optimizing {name}...")
                    optimized_strategy, _ = optimizer.comprehensive_optimize(
                        strategy_func, data,
                        target_hit_ratio=0.55,
                        target_latency_ms=2.0,
                        target_throughput_tps=1000.0
                    )
                    optimized_strategies[name] = optimized_strategy
                strategies = optimized_strategies
                print("  âœ“ HFT optimizations applied")
            except ImportError:
                print("  âš ï¸  HFT optimizer not available, using original strategies")
            except Exception as e:
                print(f"  âš ï¸  Optimization failed: {e}, using original strategies")
        
        # 3. ç­–ç•¥å›æµ‹å’Œå¯¹æ¯”ï¼ˆåŒ…å«HFTæŒ‡æ ‡ï¼‰
        print("\n[3/5] Running strategy backtest and comparison...")
        strategy_results = {}
        hft_metrics_results = {}
        
        for name, strategy_func in strategies.items():
            try:
                print(f"  - Testing strategy: {name}")
                signals = strategy_func(data)
                
                # è®¡ç®—ç®€å•æ”¶ç›Š
                if isinstance(signals, pd.Series):
                    returns = data['close'].pct_change()
                    strategy_returns = signals.shift(1) * returns
                    cumulative_returns = (1 + strategy_returns).cumprod()
                    total_return = cumulative_returns.iloc[-1] - 1 if len(cumulative_returns) > 0 else 0
                    
                    strategy_results[name] = {
                        'total_return': total_return,
                        'signals': signals,
                        'returns': strategy_returns,
                        'cumulative_returns': cumulative_returns
                    }
                    print(f"    âœ“ Total Return: {total_return*100:.2f}%")
                    
                    # è®¡ç®—HFTæŒ‡æ ‡
                    if self.hft_evaluator:
                        print(f"    - Calculating HFT metrics...")
                        prices = data['close'] if 'close' in data.columns else data.iloc[:, 0]
                        
                        # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´ï¼ˆåŸºäºä¿¡å·ç”Ÿæˆæ—¶é—´ï¼‰
                        execution_times = [data.index[i] for i in range(len(data)) if signals.iloc[i] != 0][:1000]
                        
                        # å°è¯•è·å–è®¢å•ç°¿æ•°æ®
                        order_book_data = None
                        if 'bid_price' in data.columns and 'ask_price' in data.columns:
                            order_book_data = pd.DataFrame({
                                'bid_price': data.get('bid_price', prices),
                                'ask_price': data.get('ask_price', prices),
                                'bid_size': data.get('bid_size', pd.Series([1000] * len(data), index=data.index)),
                                'ask_size': data.get('ask_size', pd.Series([1000] * len(data), index=data.index))
                            })
                        
                        # æ¨¡æ‹Ÿäº¤æ˜“å’Œå–æ¶ˆæ—¥å¿—ï¼ˆç®€åŒ–ç‰ˆï¼‰
                        trade_log = []
                        cancel_log = []
                        for i, (idx, signal) in enumerate(signals.items()):
                            if signal != 0 and i < len(prices):
                                price = prices.iloc[i] if i < len(prices) else prices.iloc[-1]
                                trade_log.append({
                                    'execution_price': price * (1 + np.random.randn() * 0.0001),  # æ¨¡æ‹Ÿslippage
                                    'intended_price': price,
                                    'timestamp': idx
                                })
                                # æ¨¡æ‹Ÿä¸€äº›å–æ¶ˆè®¢å•
                                if np.random.rand() < 0.1:  # 10%çš„è®¢å•è¢«å–æ¶ˆ
                                    cancel_log.append({'timestamp': idx})
                        
                        hft_metrics = self.hft_evaluator.evaluate_strategy(
                            signals=signals,
                            prices=prices,
                            execution_times=execution_times if execution_times else None,
                            order_book_data=order_book_data,
                            trade_log=trade_log if trade_log else None,
                            cancel_log=cancel_log if cancel_log else None
                        )
                        
                        hft_metrics_results[name] = hft_metrics
                        print(f"      âœ“ Hit Ratio: {hft_metrics.hit_ratio*100:.2f}%")
                        print(f"      âœ“ Latency Jitter: {hft_metrics.latency_jitter:.2f} ms")
                        print(f"      âœ“ Alpha Decay: {hft_metrics.alpha_decay_ms:.2f} ms")
                        print(f"      âœ“ Slippage: {hft_metrics.slippage_bps:.2f} bps")
                        print(f"      âœ“ Throughput: {hft_metrics.throughput_tps:.2f} TPS")
            except Exception as e:
                print(f"    âœ— Error testing {name}: {e}")
                import traceback
                traceback.print_exc()
                strategy_results[name] = {'error': str(e)}
        
        # 4. é£é™©æ§åˆ¶
        print("\n[4/5] Applying risk control...")
        risk_results = {}
        
        for name, result in strategy_results.items():
            if 'error' in result:
                continue
            try:
                returns = result.get('returns', pd.Series())
                if len(returns) > 0:
                    volatility = returns.std() * np.sqrt(self.periods_per_year)
                    sharpe = (returns.mean() * self.periods_per_year - self.risk_free_rate) / volatility if volatility > 0 else 0
                    
                    risk_results[name] = {
                        'volatility': volatility,
                        'sharpe_ratio': sharpe,
                        'max_drawdown': self._calculate_max_drawdown(result.get('cumulative_returns', pd.Series()))
                    }
                    print(f"  - {name}: Sharpe={sharpe:.2f}, Vol={volatility*100:.2f}%")
            except Exception as e:
                print(f"  âœ— Error calculating risk for {name}: {e}")
        
        # 5. ä»“ä½ç®¡ç†å’Œæ‰§è¡Œ
        print("\n[5/5] Position management and execution...")
        position_results = {}
        
        # é€‰æ‹©æœ€ä½³ç­–ç•¥
        best_strategy = None
        best_sharpe = -np.inf
        
        for name, risk in risk_results.items():
            sharpe = risk.get('sharpe_ratio', -np.inf)
            if sharpe > best_sharpe:
                best_sharpe = sharpe
                best_strategy = name
        
        if best_strategy:
            print(f"  âœ“ Best strategy selected: {best_strategy} (Sharpe: {best_sharpe:.2f})")
            
            # è®¡ç®—ä»“ä½
            if best_strategy in strategy_results:
                signals = strategy_results[best_strategy]['signals']
                positions = self._calculate_positions(signals, data)
                position_results[best_strategy] = {
                    'positions': positions,
                    'total_trades': (signals.diff() != 0).sum()
                }
                print(f"  âœ“ Position management completed: {position_results[best_strategy]['total_trades']} trades")
        else:
            print("  âš ï¸  No valid strategy found for position management")
        
        # æ±‡æ€»ç»“æœ
        result = {
            'data_info': {
                'n_records': len(data),
                'date_range': (str(data.index[0]), str(data.index[-1]))
            },
            'strategies_tested': list(strategies.keys()),
            'strategy_results': strategy_results,
            'risk_results': risk_results,
            'hft_metrics': {k: v.to_dict() if hasattr(v, 'to_dict') else v for k, v in hft_metrics_results.items()},
            'best_strategy': best_strategy,
            'position_results': position_results,
            'timestamp': datetime.now().isoformat()
        }
        
        print("\n" + "=" * 80)
        print("Complete Flow Finished Successfully")
        print("=" * 80)
        print(f"\nBest Strategy: {best_strategy}")
        if best_strategy and best_strategy in risk_results:
            risk = risk_results[best_strategy]
            print(f"  Sharpe Ratio: {risk.get('sharpe_ratio', 0):.2f}")
            print(f"  Volatility: {risk.get('volatility', 0)*100:.2f}%")
            print(f"  Max Drawdown: {risk.get('max_drawdown', 0)*100:.2f}%")
        
        # æ‰“å°HFTæŒ‡æ ‡æ‘˜è¦
        if hft_metrics_results:
            print("\n" + "=" * 80)
            print("HFT Metrics Summary")
            print("=" * 80)
            for name, metrics in hft_metrics_results.items():
                if hasattr(metrics, 'hit_ratio'):
                    print(f"\n{name}:")
                    print(f"  Hit Ratio: {metrics.hit_ratio*100:.2f}%")
                    print(f"  Latency Jitter: {metrics.latency_jitter:.2f} ms")
                    print(f"  Cancel-to-Trade Ratio: {metrics.cancel_to_trade_ratio:.2f}")
                    print(f"  Alpha Decay: {metrics.alpha_decay_ms:.2f} ms")
                    print(f"  Slippage: {metrics.slippage_bps:.2f} bps")
                    print(f"  Throughput: {metrics.throughput_tps:.2f} TPS")
        
        return result
    
    def _calculate_max_drawdown(self, cumulative_returns: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        if len(cumulative_returns) == 0:
            return 0.0
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max) / running_max
        return abs(drawdown.min())
    
    def _calculate_positions(self, signals: pd.Series, data: pd.DataFrame) -> pd.Series:
        """æ ¹æ®ä¿¡å·è®¡ç®—ä»“ä½"""
        # ç®€å•å®ç°ï¼šä¿¡å·ä¸º1æ—¶æ»¡ä»“ï¼Œ-1æ—¶ç©ºä»“ï¼Œ0æ—¶ä¿æŒ
        positions = signals.copy()
        positions[positions > 0] = 1.0  # æ»¡ä»“
        positions[positions < 0] = -1.0  # åšç©º
        positions[positions == 0] = 0.0  # ç©ºä»“
        return positions.fillna(0)

